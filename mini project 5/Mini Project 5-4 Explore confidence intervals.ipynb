{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d25eed62-5910-4d10-a976-c18c4f7d99f7"
   },
   "source": [
    "# Mini Project 5-4 Explore confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b50579ec-09df-4bb1-ad5a-d28f4790ca16"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a8992ac-22d5-41db-aa09-263b464950e0"
   },
   "source": [
    "The Air Quality Index (AQI) is the Environmental Protection Agency's index for reporting air quality. A value close to 0 signals little to no public health concern, while higher values are associated with increased risk to public health. The United States is considering a new federal policy that would create a subsidy for renewable energy in states observing an average AQI of 10 or above. <br>\n",
    "\n",
    "You've just started your new role as a data analyst in the Strategy division of Ripple Renewable Energy (RRE). **RRE operates in the following U.S. states: `California`, `Florida`, `Michigan`, `Ohio`, `Pennsylvania`, `Texas`.** You've been tasked with constructing an analysis which identifies which of these states are most likely to be affected, should the new federal policy be enacted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e4e3b8a-b5f9-4fe1-a824-0bd3aece693c"
   },
   "source": [
    "Your manager has requested that you do the following for your analysis:\n",
    "1. Provide a summary of the mean AQI for the states in which RRE operates.\n",
    "2. Construct a boxplot visualization for AQI of these states using `seaborn`.\n",
    "3. Evaluate which state(s) may be most affected by this policy, based on the data and your boxplot visualization.\n",
    "4. Construct a confidence interval for the RRE state with the highest mean AQI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b4dc9a5-d724-4696-a704-57fefa9d5938"
   },
   "source": [
    "## Step 1: Imports\n",
    "\n",
    "### Import packages\n",
    "\n",
    "Import `pandas` and `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0b3d0e1c-23b9-4491-82a5-ac1e4bd36f30"
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4f7c0d0-027e-475a-bce5-ad96d059cd04"
   },
   "source": [
    "### Load the dataset\n",
    "\n",
    "The dataset provided gives national Air Quality Index (AQI) measurements by state over time.  `Pandas` is used to import the file `c4_epa_air_quality.csv` as a DataFrame named `aqi`. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions.\n",
    "\n",
    "*Note: For the purposes of your analysis, you can assume this data is randomly sampled from a larger population.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1ce82ed7-cf32-4028-ac77-a377e7638458",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date_local</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>units_of_measure</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Buckeye</td>\n",
       "      <td>BUCKEYE</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Belmont</td>\n",
       "      <td>Shadyside</td>\n",
       "      <td>Shadyside</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Teton</td>\n",
       "      <td>Not in a city</td>\n",
       "      <td>Yellowstone National Park - Old Faithful Snow ...</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>North East Waste (NEW)</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Polk</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>CARPENTER</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>0.215789</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  date_local    state_name   county_name      city_name  \\\n",
       "0           0  2018-01-01       Arizona      Maricopa        Buckeye   \n",
       "1           1  2018-01-01          Ohio       Belmont      Shadyside   \n",
       "2           2  2018-01-01       Wyoming         Teton  Not in a city   \n",
       "3           3  2018-01-01  Pennsylvania  Philadelphia   Philadelphia   \n",
       "4           4  2018-01-01          Iowa          Polk     Des Moines   \n",
       "\n",
       "                                     local_site_name   parameter_name  \\\n",
       "0                                            BUCKEYE  Carbon monoxide   \n",
       "1                                          Shadyside  Carbon monoxide   \n",
       "2  Yellowstone National Park - Old Faithful Snow ...  Carbon monoxide   \n",
       "3                             North East Waste (NEW)  Carbon monoxide   \n",
       "4                                          CARPENTER  Carbon monoxide   \n",
       "\n",
       "    units_of_measure  arithmetic_mean  aqi  \n",
       "0  Parts per million         0.473684    7  \n",
       "1  Parts per million         0.263158    5  \n",
       "2  Parts per million         0.111111    2  \n",
       "3  Parts per million         0.300000    3  \n",
       "4  Parts per million         0.215789    3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df=pd.read_csv(\"c4_epa_air_quality.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLW4ftpm15LA"
   },
   "source": [
    "## Step 2: Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOPQ6EL9ZmrB"
   },
   "source": [
    "**Question:** What time range does this data cover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "date_str = \"2018-01-01\"\n",
    "date_time = pd.to_datetime(date_str)\n",
    "print(date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw0U5NWpZ1wp"
   },
   "source": [
    "**Question:** What are the minimum and maximum AQI values observed in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum aqi value: 0\n",
      "Maximum aqi value: 50\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "min_aqi = df['aqi'].min()\n",
    "max_aqi = df['aqi'].max()\n",
    "\n",
    "print(f\"Minimum aqi value: {min_aqi}\")\n",
    "print(f\"Maximum aqi value: {max_aqi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWBj7cKZZ_du"
   },
   "source": [
    "**Question:** Are all states equally represented in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_name\n",
      "California              66\n",
      "Arizona                 14\n",
      "Ohio                    12\n",
      "Florida                 12\n",
      "Texas                   10\n",
      "New York                10\n",
      "Pennsylvania            10\n",
      "Michigan                 9\n",
      "Colorado                 9\n",
      "Minnesota                7\n",
      "New Jersey               6\n",
      "Indiana                  5\n",
      "North Carolina           4\n",
      "Massachusetts            4\n",
      "Maryland                 4\n",
      "Oklahoma                 4\n",
      "Virginia                 4\n",
      "Nevada                   4\n",
      "Connecticut              4\n",
      "Kentucky                 3\n",
      "Missouri                 3\n",
      "Wyoming                  3\n",
      "Iowa                     3\n",
      "Hawaii                   3\n",
      "Utah                     3\n",
      "Vermont                  3\n",
      "Illinois                 3\n",
      "New Hampshire            2\n",
      "District Of Columbia     2\n",
      "New Mexico               2\n",
      "Montana                  2\n",
      "Oregon                   2\n",
      "Alaska                   2\n",
      "Georgia                  2\n",
      "Washington               2\n",
      "Idaho                    2\n",
      "Nebraska                 2\n",
      "Rhode Island             2\n",
      "Tennessee                2\n",
      "Maine                    2\n",
      "South Carolina           1\n",
      "Puerto Rico              1\n",
      "Arkansas                 1\n",
      "Kansas                   1\n",
      "Mississippi              1\n",
      "Alabama                  1\n",
      "Louisiana                1\n",
      "Delaware                 1\n",
      "South Dakota             1\n",
      "West Virginia            1\n",
      "North Dakota             1\n",
      "Wisconsin                1\n",
      "Name: count, dtype: int64\n",
      "states are not equally represented.\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "state_counts = df['state_name'].value_counts()\n",
    "\n",
    "# Display the counts for each state\n",
    "print(state_counts)\n",
    "\n",
    "# Check if all state are equally represented\n",
    "if state_counts.nunique() == 1:\n",
    "    print(\"All states are equally represented.\")\n",
    "else:\n",
    "    print(\"states are not equally represented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd48d0f0-3f90-455e-87a1-0da43fcac202"
   },
   "source": [
    "## Step 3: Statistical tests\n",
    "\n",
    "### Summarize the mean AQI for RRE states\n",
    "\n",
    "Start with your first deliverable. Summarize the mean AQI for the states in which RRE operates (California, Florida, Michigan, Ohio, Pennsylvania, and Texas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac18cb1b-40ca-4de3-bc0a-08be82f64781"
   },
   "source": [
    "### Find your margin of error (ME)\n",
    "\n",
    "Recall **margin of error = z * standard error**, where z is the appropriate z-value for the given confidence level. To calculate your margin of error:\n",
    "\n",
    "- Find your z-value. \n",
    "- Find the approximate z for common confidence levels.\n",
    "- Calculate your **standard error** estimate. \n",
    "\n",
    "| Confidence Level | Z Score |\n",
    "| --- | --- |\n",
    "| 90% | 1.65 |\n",
    "| 95% | 1.96 |\n",
    "| 99% | 2.58 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b0d173b-06d4-4e82-81d8-092b24132bd2"
   },
   "source": [
    "### Calculate your interval\n",
    "\n",
    "Calculate both a lower and upper limit surrounding your sample mean to create your interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f83a7ba7-afdd-4d8c-8b78-849cff363180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 21.7\n",
      "Lower Limit: 20.116489986081305\n",
      "Upper Limit: 23.283510013918693\n"
     ]
    }
   ],
   "source": [
    "# Calculate your confidence interval (upper and lower limits).\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (example)\n",
    "data = [23, 21, 18, 22, 24, 19, 20, 25, 23, 22]\n",
    "\n",
    "# Step 1: Calculate the sample mean\n",
    "sample_mean = np.mean(data)\n",
    "\n",
    "# Step 2: Calculate the standard deviation and standard error of the mean (SEM)\n",
    "sample_std = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "sample_size = len(data)\n",
    "sem = sample_std / np.sqrt(sample_size)\n",
    "\n",
    "# Step 3: Determine the critical value (e.g., using t-distribution for small sample size)\n",
    "confidence_level = 0.95  # 95% confidence\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=sample_size - 1)\n",
    "\n",
    "# Step 4: Calculate the margin of error\n",
    "margin_of_error = t_critical * sem\n",
    "\n",
    "# Step 5: Calculate the confidence interval\n",
    "lower_limit = sample_mean - margin_of_error\n",
    "upper_limit = sample_mean + margin_of_error\n",
    "\n",
    "# Output the results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Lower Limit: {lower_limit}\")\n",
    "print(f\"Upper Limit: {upper_limit}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82e06ed3-2ec3-4851-b3df-2c6d969ea616"
   },
   "source": [
    "### Alternative: Construct the interval using `scipy.stats.norm.interval()`\n",
    "\n",
    "`scipy` presents a simpler solution to developing a confidence interval. To use this, first import the `stats` module from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0b6d2ecc-03ff-47ab-9d2d-57857fc38ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 21.7\n",
      "Confidence Interval: (20.328025210821963, 23.071974789178036)\n"
     ]
    }
   ],
   "source": [
    "# Import stats from scipy.\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (example)\n",
    "data = [23, 21, 18, 22, 24, 19, 20, 25, 23, 22]\n",
    "\n",
    "# Calculate the sample mean and standard deviation\n",
    "sample_mean = np.mean(data)\n",
    "sample_std = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "sample_size = len(data)\n",
    "\n",
    "# Confidence level\n",
    "confidence_level = 0.95  # 95% confidence\n",
    "\n",
    "# Step 1: Calculate the standard error\n",
    "sem = sample_std / np.sqrt(sample_size)\n",
    "\n",
    "# Step 2: Use norm.interval to calculate the confidence interval\n",
    "lower_limit, upper_limit = stats.norm.interval(\n",
    "    confidence_level, \n",
    "    loc=sample_mean, \n",
    "    scale=sem\n",
    ")\n",
    "\n",
    "# Output the results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Confidence Interval: ({lower_limit}, {upper_limit})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba8af068-f28e-4c29-82c9-238bc0f16ed1"
   },
   "source": [
    "## Step 4: Results and evaluation\n",
    "\n",
    "### Recalculate your confidence interval\n",
    "\n",
    "Provide your chosen `confidence_level`, `sample_mean`, and `standard_error` to `stats.norm.interval()` and recalculate your confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f908eb99-ce5c-472f-891e-80a47cef5fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Level: 0.95\n",
      "Sample Mean: 21.7\n",
      "Standard Error: 0.7\n",
      "Lower Limit: 20.328025210821963\n",
      "Upper Limit: 23.071974789178036\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (example)\n",
    "data = [23, 21, 18, 22, 24, 19, 20, 25, 23, 22]\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = np.mean(data)\n",
    "\n",
    "# Calculate the sample standard deviation and sample size\n",
    "sample_std = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "sample_size = len(data)\n",
    "\n",
    "# Define the confidence level\n",
    "confidence_level = 0.95  # 95% confidence interval\n",
    "\n",
    "# Calculate the standard error of the mean (SEM)\n",
    "sem = sample_std / np.sqrt(sample_size)\n",
    "\n",
    "# Use scipy.stats.norm.interval() to calculate the confidence interval\n",
    "lower_limit, upper_limit = stats.norm.interval(confidence_level, loc=sample_mean, scale=sem)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Confidence Level: {confidence_level}\")\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Standard Error: {sem}\")\n",
    "print(f\"Lower Limit: {lower_limit}\")\n",
    "print(f\"Upper Limit: {upper_limit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feb3e273-1aab-4965-bceb-8b8933c743b5"
   },
   "source": [
    "# Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are some key takeaways that you learned from this project?**\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What findings would you share with others?**\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would you convey to external readers?**\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IVWUekbeFEq"
   },
   "source": [
    "**References**\n",
    "\n",
    "[seaborn.boxplot â€” seaborn 0.12.1 documentation](https://seaborn.pydata.org/generated/seaborn.boxplot.html). (n.d.). "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
